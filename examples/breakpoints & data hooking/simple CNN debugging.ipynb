{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "#########################################\n",
    "# 1. Define a simple CNN with 3 conv layers\n",
    "#########################################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # conv1: from 4x4 input → output remains 4x4\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        # conv2: from 4x4 → 2x2 (stride=2)\n",
    "        self.conv2 = nn.Conv2d(1, 1, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        # conv3: from 2x2 → 1x1 (stride=2)\n",
    "        self.conv3 = nn.Conv2d(1, 1, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.fcn = nn.Linear(1, 10, bias=False)  # not used for interaction\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        a1 = (self.conv1(x))    # shape: (1,1,4,4)\n",
    "        a2 = (self.conv2(a1))     # shape: (1,1,2,2)\n",
    "        a3 = (self.conv3(a2))     # shape: (1,1,1,1)\n",
    "        return a3\n",
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Extraction & Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 2. Register hooks to capture gradients\n",
    "#########################################\n",
    "activation_gradients = {}\n",
    "gradient_flows = {}\n",
    "def get_activation_grad(name, connet2name=None):\n",
    "    def hook(module, grad_input, grad_output):\n",
    "        if name is not None:\n",
    "            # Lấy grad_out: shape [N, C_out, H_out, W_out]\n",
    "            grad_out = grad_output[0].detach()\n",
    "            N, C_out, H_out, W_out = grad_out.shape\n",
    "            \n",
    "            # Lấy weight của module: shape [C_out, C_in, kH, kW]\n",
    "            weight = module.weight  \n",
    "            C_out_w, C_in, kH, kW = weight.shape\n",
    "            assert C_out == C_out_w, \"Mismatch in output channels.\"\n",
    "\n",
    "            # Chuyển weight thành dạng ma trận: [C_out, C_in*kH*kW]\n",
    "            weight_reshaped = weight.view(C_out, -1)\n",
    "            \n",
    "            # Reshape grad_out thành [N, C_out, Len_out] với Len_out = H_out * W_out\n",
    "            Len_out = H_out * W_out\n",
    "            grad_out_reshaped = grad_out.view(N, C_out, Len_out)\n",
    "\n",
    "            # Tính grad_input_cols: [N, C_in*kH*kW, Len_out]\n",
    "            grad_input_cols = torch.matmul(weight_reshaped.t(), grad_out_reshaped)\n",
    "            \n",
    "            # Giả sử batch size N=1\n",
    "            grad_input_cols = grad_input_cols[0]  # [C_in*kH*kW, Len_out]\n",
    "\n",
    "            # Lấy kích thước input từ grad_input[0]: [N, C_in, H_in, W_in]\n",
    "            H_in, W_in = grad_input[0].shape[2:]\n",
    "            Len_in = H_in * W_in\n",
    "\n",
    "            # Xây dựng ánh xạ từ các patch đến các vị trí trên input:\n",
    "            # Tạo tensor chứa các chỉ số của các ô input, shape: [1, 1, H_in, W_in]\n",
    "            input_indices = torch.arange(Len_in, device=grad_out.device).view(1, 1, H_in, W_in).float()+1\n",
    "            # Sử dụng F.unfold để lấy ma trận ánh xạ, shape: [C_in*kH*kW, Len_out]\n",
    "            idx_map = (F.unfold(input_indices, kernel_size=module.kernel_size, \n",
    "                                dilation=module.dilation, padding=module.padding, stride=module.stride)[0])\n",
    "\n",
    "            # Khởi tạo gradient_flows với kích thước (Len_in, Len_out)\n",
    "            gradient_flow = torch.zeros(Len_in+1, Len_out, device=grad_out.device)\n",
    "            # Sử dụng scatter_add_ để cộng các giá trị từ grad_input_cols vào gradient_flows\n",
    "            # Cho mỗi phần tử tại vị trí (p, j) trong grad_input_cols, ta cộng vào gradient_flows tại (idx_map[p,j], j)\n",
    "            gradient_flow.scatter_add_(0, idx_map.long(), grad_input_cols)\n",
    "            gradient_flow = (gradient_flow[1:,:])\n",
    "            # print((grad_input[0]).cpu().numpy().reshape(-1))\n",
    "            # print(gradient_flow.cpu().numpy().sum(axis=-1,keepdims=False))\n",
    "            assert np.abs(gradient_flow.cpu().numpy().sum(axis=-1,keepdims=False)-(grad_input[0]).cpu().numpy().reshape(-1)).sum() < 1e-7, \"Mismatch in gradient values.\"\n",
    "            gradient_flow = torch.abs(gradient_flow)\n",
    "            gradient_flow[gradient_flow>1e-5] = 1.\n",
    "            gradient_flow[gradient_flow<=1e-5] = .99\n",
    "\n",
    "            # Lưu kết quả vào activation_gradients\n",
    "            gradient_flows[(name, connet2name)] = gradient_flow.cpu().numpy()  # kích thước: (Len_in, Len_out)\n",
    "            \n",
    "            activation_gradients[name] = (gradient_flows[(name, connet2name)]).sum(axis=-1,keepdims=False).reshape(H_in, W_in)\n",
    "            activation_gradients[connet2name] = (gradient_flows[(name, connet2name)]).sum(axis=0,keepdims=False).reshape(H_out, W_out)\n",
    "    return hook\n",
    "\n",
    "model.conv1.register_backward_hook(get_activation_grad(None, \"conv1\"))\n",
    "model.conv2.register_backward_hook(get_activation_grad(\"conv1\", \"conv2\"))\n",
    "model.conv3.register_backward_hook(get_activation_grad(\"conv2\", \"conv3\"))\n",
    "\n",
    "#########################################\n",
    "# 3. Run forward/backward on a random input\n",
    "#########################################\n",
    "input_tensor = torch.randn(1, 1, 4, 4)\n",
    "target = torch.randn(1, 1, 4, 4).long()\n",
    "optimizer.zero_grad()\n",
    "a3 = model(input_tensor)\n",
    "loss = (a3.reshape(1,-1) - target[0,0,2,2].reshape(1,-1)).mean()  # use conv3 output for loss\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save gradient flow information, includes: \n",
    "- activation_gradients: dict of aggregated weights of nodes at each layer. \n",
    "- gradient_flows: dict of values of gradient flows between adjacent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'debug_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae85de2e1b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"debug_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m flow_info = {\"activation_gradients\": activation_gradients, \n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'debug_data'"
     ]
    }
   ],
   "source": [
    "import os,pickle\n",
    "\n",
    "os.mkdir(\"debug_data\")\n",
    "\n",
    "flow_info = {\"activation_gradients\": activation_gradients, \n",
    "             \"gradient_flows\": gradient_flows}\n",
    "with open('debug_data/flow_info.pkl', 'wb') as f:\n",
    "    pickle.dump(flow_info, f)\n",
    "np.save('debug_data/input_representation.npy', input_tensor[0,0,:,:].cpu().numpy())\n",
    "np.save('debug_data/target_representation.npy', target[0,0,:,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering the Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\vnittest\\\\examples\\\\breakpoints & data hooking\\\\debug_data\\\\'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "debug_dir = os.path.join(os.getcwd(), \"debug_data\") + \"\\\\\"\n",
    "debug_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['vnittest', 'C:\\\\Users\\\\Admin\\\\Documents\\\\GitHub\\\\vnittest\\\\examples\\\\breakpoints & data hooking\\\\debug_data\\\\'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"vnittest\", debug_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
